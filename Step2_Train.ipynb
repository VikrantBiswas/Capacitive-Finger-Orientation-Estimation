{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this notebook is based on https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/02_Convolutional_Neural_Network.ipynb the copied parts are lincened under MIT license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorflowFolder = \".\"\n",
    "STORAGE_NAME = 'model'\n",
    "\n",
    "# If no GPU support: toggle the next two lines\n",
    "# GPU_USE = '/cpu:0' \n",
    "GPU_USE= '/gpu:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.python.framework import dtypes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from queue import Queue\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    #with tf.name_scope(name):\n",
    "    if (len(var.shape) == 0):\n",
    "        tf.summary.scalar('mean/' + name, var)\n",
    "    else:\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean/' + name, mean)\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev/' + name, stddev)\n",
    "        tf.summary.scalar('max/' + name, tf.reduce_max(var))\n",
    "        tf.summary.scalar('min/' + name, tf.reduce_min(var))\n",
    "        #tf.histogram_summary(name, tf.to_float(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self, images, labels, one_hot=False, dtype=dtypes.float32):\n",
    "        \"\"\"Construct a DataSet.\n",
    "        one_hot arg is used only if fake_data is true.    `dtype` can be either\n",
    "        `uint8` to leave the input as `[0, 255]`, or `float32` to rescale into\n",
    "        `[0, 1]`.\n",
    "        \"\"\"\n",
    "        dtype = dtypes.as_dtype(dtype).base_dtype\n",
    "        if dtype not in (dtypes.uint8, dtypes.float32):\n",
    "            raise TypeError('Invalid image dtype %r, expected uint8 or float32' % dtype)\n",
    "        assert images.shape[0] == labels.shape[0], ('images.shape: %s labels.shape: %s' % (images.shape, labels.shape))\n",
    "        self._num_examples = images.shape[0]\n",
    "\n",
    "        # Convert shape from [num examples, rows, columns, depth]\n",
    "        # to [num examples, rows*columns] (assuming depth == 1)\n",
    "        if dtype == dtypes.float32:\n",
    "            # Convert from [0, 255] -> [0.0, 1.0].'\n",
    "            images = np.multiply(images, 1.0 / 255.0)\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "    \n",
    "    def reset(self):\n",
    "        self._epochs_completed = 0\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        return self._images[start:end], self._labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data_sets(datapath,\n",
    "                   one_hot=False,\n",
    "                   dtype=dtypes.float32,\n",
    "                   split = (80, 20)):\n",
    "    print(\"Loading ...\")\n",
    "    df = pd.read_pickle(datapath)\n",
    "\n",
    "    # We need to sort the participant in order to ensure that we never use traings data in a test\n",
    "    ps = np.array(sorted(df.Participant.unique()))\n",
    "    num_pt = len(ps)\n",
    "    x1 = math.floor(len(ps) * split[0] / 100.0)\n",
    "    split_train = ps[:x1]\n",
    "    x2 = math.floor(len(ps) * split[1] / 100.0)\n",
    "    split_test = ps[x1:]\n",
    "    \n",
    "    print (\"Slpit by samples : %.2f / %.2f \"% (np.round(len(split_train) / len(ps),2), np.round(len(split_test) / len(ps),2)))\n",
    "    \n",
    "    n_input_x = df.MatrixCroppedSameSize.iloc[0].shape[0]\n",
    "    n_input_y = df.MatrixCroppedSameSize.iloc[0].shape[1]\n",
    "    n_input_channels = 1\n",
    "    \n",
    "    df2 = df[df.Participant.isin(split_train)]\n",
    "    xList = []\n",
    "    for x in np.array(df2.MatrixCroppedSameSize):\n",
    "        xList.append(x.reshape(n_input_x, n_input_y, n_input_channels))\n",
    "    train_images = np.array(xList)\n",
    "    train_labels = np.concatenate((np.array(df2.Pitch).reshape(len(df2),1), np.array(df2.Yaw).reshape(len(df2),1)), axis=1)\n",
    "    \n",
    "        \n",
    "    df2 = df[df.Participant.isin(split_test)]\n",
    "    xList = []\n",
    "    for x in np.array(df2.MatrixCroppedSameSize):\n",
    "        xList.append(x.reshape(n_input_x, n_input_y, n_input_channels))\n",
    "    test_images = np.array(xList)    \n",
    "    test_labels = np.concatenate((np.array(df2.Pitch).reshape(len(df2),1), np.array(df2.Yaw).reshape(len(df2),1)), axis=1)\n",
    "    \n",
    "    seed = np.random.randint(0, 10000000)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(train_images)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(train_labels)\n",
    "    \n",
    "    seed = np.random.randint(0, 10000000)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(test_images)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(test_labels)\n",
    "    \n",
    "    train = DataSet(train_images, train_labels, dtype=dtype)\n",
    "    test = DataSet(test_images, test_labels, dtype=dtype)\n",
    "    \n",
    "    del df\n",
    "    del df2\n",
    "    print(\"Done!\")\n",
    "    return base.Datasets(train=train, test=test, validation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ...\n",
      "Slpit by samples : 0.79 / 0.21 \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = read_data_sets('./data/all_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t368836\n",
      "- Test-set:\t88432\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t%i\" % len(data.train.labels))\n",
    "print(\"- Test-set:\\t%i\" % len(data.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_shape = (data.train.images[0].shape[0], data.train.images[0].shape[1])\n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image.reshape(img_shape))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20,10))\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape))\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+cAAAI/CAYAAAAV5KhKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktQxg3NJkiRJkjr2/1pw9W7yishcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d043c6978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = data.test.images[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = data.test.labels[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    #return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    global weightsCounter, GPU_USE\n",
    "    weightsCounter = weightsCounter + 1\n",
    "    with tf.device(GPU_USE):\n",
    "        return vs.get_variable(\"weights\"+str(weightsCounter), shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def new_biases(length):\n",
    "    global biasesCounter, GPU_USE, bias_start\n",
    "    biasesCounter = biasesCounter + 1\n",
    "    with tf.device(GPU_USE):\n",
    "        return vs.get_variable(\"bias\"+str(biasesCounter), [length], initializer=init_ops.constant_initializer(bias_start))\n",
    "        #return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "        \n",
    "# Helper-function for creating a new Convolutional Layer\n",
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    global GPU_USE\n",
    "    with tf.device(GPU_USE):\n",
    "        # Shape of the filter-weights for the convolution.\n",
    "        # This format is determined by the TensorFlow API.\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights aka. filters with the given shape.\n",
    "        weights = new_weights(shape=shape)\n",
    "\n",
    "        # Create new biases, one for each filter.\n",
    "        biases = new_biases(length=num_filters)\n",
    "\n",
    "        # Create the TensorFlow operation for convolution.\n",
    "        # Note the strides are set to 1 in all dimensions.\n",
    "        # The first and last stride must always be 1,\n",
    "        # because the first is for the image-number and\n",
    "        # the last is for the input-channel.\n",
    "        # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "        # is moved 2 pixels across the x- and y-axis of the image.\n",
    "        # The padding is set to 'SAME' which means the input image\n",
    "        # is padded with zeroes so the size of the output is the same.\n",
    "        \n",
    "        # strides = [batch, height, width, challens]\n",
    "        layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "        # A bias-value is added to each filter-channel.\n",
    "        layer += biases\n",
    "\n",
    "        # Use pooling to down-sample the image resolution?\n",
    "        if use_pooling:\n",
    "            # This is 2x2 max-pooling, which means that we\n",
    "            # consider 2x2 windows and select the largest value\n",
    "            # in each window. Then we move 2 pixels to the next window.\n",
    "            layer = tf.nn.max_pool(value=layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "         \n",
    "        # Rectified Linear Unit (ReLU).\n",
    "        # It calculates max(x, 0) for each input pixel x.\n",
    "        # This adds some non-linearity to the formula and allows us\n",
    "        # to learn more complicated functions.\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "        # Note that ReLU is normally executed before the pooling,\n",
    "        # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "        # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "        # We return both the resulting layer and the filter-weights\n",
    "        # because we will plot the weights later.\n",
    "        return layer, weights\n",
    "\n",
    "# Helper-function for flattening a layer\n",
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "\n",
    "# Helper-function for creating a new Fully-Connected Layer\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True,\n",
    "                 name=None): # Use Rectified Linear Unit (ReLU)?\n",
    "    global GPU_USE\n",
    "    with tf.device(GPU_USE):\n",
    "        # Create new weights and biases.\n",
    "        weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "        biases = new_biases(length=num_outputs)\n",
    "\n",
    "        # Calculate the layer as the matrix multiplication of\n",
    "        # the input and weights, and then add the bias-values.\n",
    "        if name == None: \n",
    "            layer = tf.add(tf.matmul(input, weights), biases)\n",
    "        else:\n",
    "            layer = tf.add(tf.matmul(input, weights), biases, name=name)\n",
    "\n",
    "        # Use ReLU?\n",
    "        if use_relu:\n",
    "            #layer = tf.contrib.layers.batch_norm(layer, center=True, scale=True)\n",
    "            layer = tf.nn.softplus(layer)\n",
    "\n",
    "        return layer, weights, biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting session 1503618587 2017-08-25 01:49:47\n",
      "SAVE_PATH: ./model/1503618587/\n",
      "0 RMSE: 36.54 RMSE-P: 15.25 RMSE-Y: 31.45 e: 35.96 E-P: 12.47 E-Y: 23.50 std: 23.36 std-P: 8.79 std-Y: 20.91 time: 0:00:48\n",
      "1 RMSE: 29.54 RMSE-P: 13.51 RMSE-Y: 26.39 e: 30.44 E-P: 10.75 E-Y: 19.69 std: 19.83 std-P: 8.18 std-Y: 17.57 time: 0:02:24\n",
      "2 RMSE: 28.80 RMSE-P: 12.86 RMSE-Y: 25.58 e: 29.06 E-P: 10.25 E-Y: 18.81 std: 19.35 std-P: 7.77 std-Y: 17.34 time: 0:03:39\n",
      "3 RMSE: 28.50 RMSE-P: 13.19 RMSE-Y: 26.52 e: 29.63 E-P: 10.45 E-Y: 19.18 std: 20.64 std-P: 8.04 std-Y: 18.32 time: 0:06:04\n",
      "4 RMSE: 28.34 RMSE-P: 13.04 RMSE-Y: 24.92 e: 28.53 E-P: 10.32 E-Y: 18.21 std: 19.29 std-P: 7.96 std-Y: 17.01 time: 0:07:25\n",
      "5 RMSE: 27.90 RMSE-P: 12.89 RMSE-Y: 25.06 e: 28.26 E-P: 10.18 E-Y: 18.07 std: 19.66 std-P: 7.90 std-Y: 17.36 time: 0:09:23\n",
      "6 RMSE: 27.85 RMSE-P: 12.80 RMSE-Y: 24.66 e: 27.97 E-P: 10.14 E-Y: 17.84 std: 19.18 std-P: 7.81 std-Y: 17.03 time: 0:10:28\n",
      "7 RMSE: 27.21 RMSE-P: 12.55 RMSE-Y: 24.25 e: 27.59 E-P: 9.95 E-Y: 17.64 std: 18.64 std-P: 7.64 std-Y: 16.64 time: 0:12:36\n",
      "8 RMSE: 27.37 RMSE-P: 12.70 RMSE-Y: 24.41 e: 27.77 E-P: 10.03 E-Y: 17.74 std: 18.97 std-P: 7.79 std-Y: 16.77 time: 0:13:40\n",
      "9 RMSE: 27.43 RMSE-P: 13.02 RMSE-Y: 24.61 e: 28.33 E-P: 10.28 E-Y: 18.05 std: 19.20 std-P: 7.99 std-Y: 16.73 time: 0:15:17\n",
      "10 RMSE: 27.82 RMSE-P: 13.54 RMSE-Y: 24.33 e: 28.46 E-P: 10.69 E-Y: 17.77 std: 19.43 std-P: 8.31 std-Y: 16.63 time: 0:16:45\n",
      "11 RMSE: 27.38 RMSE-P: 12.76 RMSE-Y: 24.17 e: 27.91 E-P: 10.06 E-Y: 17.85 std: 18.66 std-P: 7.84 std-Y: 16.30 time: 0:18:38\n",
      "12 RMSE: 28.39 RMSE-P: 13.55 RMSE-Y: 24.45 e: 28.52 E-P: 10.68 E-Y: 17.84 std: 19.46 std-P: 8.33 std-Y: 16.71 time: 0:20:20\n",
      "13 RMSE: 28.54 RMSE-P: 13.01 RMSE-Y: 24.90 e: 28.30 E-P: 10.22 E-Y: 18.08 std: 19.59 std-P: 8.04 std-Y: 17.12 time: 0:23:35\n",
      "14 RMSE: 27.54 RMSE-P: 12.71 RMSE-Y: 24.32 e: 27.65 E-P: 9.94 E-Y: 17.71 std: 19.07 std-P: 7.93 std-Y: 16.66 time: 0:24:58\n",
      "15 RMSE: 28.01 RMSE-P: 13.79 RMSE-Y: 24.10 e: 28.90 E-P: 10.88 E-Y: 18.01 std: 18.90 std-P: 8.48 std-Y: 16.01 time: 0:28:10\n",
      "16 RMSE: 27.49 RMSE-P: 13.00 RMSE-Y: 24.08 e: 28.02 E-P: 10.20 E-Y: 17.81 std: 18.80 std-P: 8.05 std-Y: 16.20 time: 0:28:59\n",
      "17 RMSE: 28.60 RMSE-P: 12.82 RMSE-Y: 24.98 e: 28.51 E-P: 10.05 E-Y: 18.47 std: 19.26 std-P: 7.96 std-Y: 16.82 time: 0:30:21\n",
      "BREAK AFTER 17 epochs\n",
      "Time usage: 0:30:21\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "data.train.reset()\n",
    "data.test.reset()\n",
    "\n",
    "n_input_x = data.train.images[0].shape[0]\n",
    "n_input_y = data.train.images[0].shape[1]\n",
    "n_input = n_input_x * n_input_y\n",
    "n_input_channels = 1\n",
    "n_output = 2\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "\n",
    "\n",
    "data.test.cls = np.argmax(data.test.labels, axis=1)\n",
    "\n",
    "\n",
    "# Counter for total number of iterations performed so far.\n",
    "num_iterations = 4000\n",
    "train_batch_size = 100\n",
    "\n",
    "### Convolutional Layer 1.\n",
    "filter_size1 = 6\n",
    "num_filters1 = 16*2\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 6\n",
    "num_filters2 = 36*2\n",
    "\n",
    "#Convolutional Layer 3.\n",
    "filter_size3 = 7\n",
    "num_filters3 = 80*2\n",
    "             \n",
    "# Fully-connected layer.\n",
    "fc_size = 2000             # Number of neurons in fully-connected layer.\n",
    "\n",
    "\n",
    "learning_rate = 0.02\n",
    "decay_rate = 0.1\n",
    "decay_steps = num_iterations\n",
    "# learning_rate = 0.001\n",
    "# decay_rate = 0.99\n",
    "#decay_steps = num_iterations\n",
    "\n",
    "\n",
    "\n",
    "weightsCounter = -1\n",
    "biasesCounter = -1\n",
    "\n",
    "bias_start = 0.01\n",
    "\n",
    "with tf.device(GPU_USE):\n",
    "    _x = tf.placeholder(tf.float32, shape=[None, n_input_x, n_input_y, n_input_channels], name=\"input_tensor\")\n",
    "    \n",
    "    _y_true = tf.placeholder(tf.float32, shape=[None, n_output], name='y_true')\n",
    " \n",
    "    testLen = int((len(data.test.labels)/train_batch_size))*train_batch_size\n",
    "    _error = tf.Variable(tf.zeros([testLen]), dtype=tf.float32, name=\"error\", trainable=False)   \n",
    "    _errorPitch = tf.Variable(tf.zeros([testLen]), dtype=tf.float32, name=\"errorPitch\", trainable=False)\n",
    "    _errorYaw = tf.Variable(tf.zeros([testLen]), dtype=tf.float32, name=\"errorYaw\", trainable=False)    \n",
    "    \n",
    "    _RMSE = tf.Variable(0, dtype=tf.float32, name=\"errorRMSE\", trainable=False)\n",
    "    _RMSEPitch = tf.Variable(0, dtype=tf.float32, name=\"errorPitchRMSE\", trainable=False)\n",
    "    _RMSEYaw = tf.Variable(0, dtype=tf.float32, name=\"errorYawRMSE\", trainable=False)\n",
    "    \n",
    "    _global_step = tf.Variable(0, dtype=tf.int32, name=\"global_step\", trainable=False)\n",
    "    \n",
    "    \n",
    "variable_summaries(_RMSE, \"errorRMSE\")\n",
    "variable_summaries(_RMSEPitch, \"errorPitchRMSE\")\n",
    "variable_summaries(_RMSEYaw, \"errorYawRMSE\")\n",
    "\n",
    "variable_summaries(_error, \"error\")\n",
    "variable_summaries(_errorPitch, \"errorPitch\")\n",
    "variable_summaries(_errorYaw, \"errorYaw\")\n",
    "\n",
    "#layer_conv1\n",
    "t, weights_conv1 = new_conv_layer(input=_x, num_input_channels=n_input_channels, filter_size=filter_size1,\n",
    "                                  num_filters=num_filters1, use_pooling=True)\n",
    "#layer_conv2\n",
    "t, weights_conv2 = new_conv_layer(input=t, num_input_channels=num_filters1, filter_size=filter_size2,\n",
    "                                  num_filters=num_filters2, use_pooling=True)\n",
    "#layer_conv3\n",
    "t, weights_conv3 = new_conv_layer(input=t, num_input_channels=num_filters2, filter_size=filter_size3,\n",
    "                                    num_filters=num_filters3, use_pooling=True)\n",
    "\n",
    "#layer_flat\n",
    "t, num_features = flatten_layer(t)\n",
    "#layer_fc1\n",
    "t, weights_fc1, biases_fc1 = new_fc_layer(input=t, num_inputs=num_features, num_outputs=fc_size, use_relu=True)\n",
    "#layer_fc2\n",
    "t, weights_fc2, biases_f2 = new_fc_layer(input=t, num_inputs=fc_size, num_outputs=n_output, use_relu=False, name=\"output_tensor\")\n",
    "\n",
    "y_pred = t\n",
    "    \n",
    "# Definition of cost function \n",
    "def distance(predictions, targets):\n",
    "    with tf.device(GPU_USE):\n",
    "        mean= tf.reduce_mean(tf.square(tf.subtract(predictions, targets)))\n",
    "        if (mean == 0.0):\n",
    "            mean = 0.0\n",
    "        else:\n",
    "            mean = tf.sqrt(mean)\n",
    "        \n",
    "        mean = tf.reduce_mean(mean +\n",
    "            0.15*tf.nn.l2_loss(weights_fc1) +\n",
    "            0.15*tf.nn.l2_loss(weights_fc2))\n",
    "        return mean\n",
    "    \n",
    "cost = distance(y_pred, _y_true)\n",
    "\n",
    "with tf.device(GPU_USE):\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate, _global_step, decay_steps, decay_rate)\n",
    "    optimizer =  tf.train.MomentumOptimizer(learning_rate, momentum=0.9).minimize(cost, global_step=_global_step)\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "timestamp = int(time.time())\n",
    "print (\"Starting session %i %s\" % (timestamp, datetime.datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')))\n",
    "SAVE_PATH = tensorflowFolder + '/' + STORAGE_NAME + '/'+ str(timestamp) + '/'\n",
    "print (\"SAVE_PATH: %s\" % SAVE_PATH)\n",
    "train_writer = tf.summary.FileWriter(SAVE_PATH, graph=tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=False\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.1\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "\n",
    "breakQueue=Queue()\n",
    "breakEpochs = 15\n",
    "with tf.device(GPU_USE):\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Start-time used for printing tifme-usage below.\n",
    "        start_time = time.time()\n",
    "\n",
    "        len(data.train.images)\n",
    "        for i in range(num_iterations):\n",
    "            epochs = data.train.epochs_completed\n",
    "            while True:\n",
    "                x_batch, y_batch = data.train.next_batch(train_batch_size)\n",
    "\n",
    "                #x_batch = x_batch.reshape([train_batch_size, x_batch[0].shape[0] * x_batch[0].shape[1]])\n",
    "                _ = sess.run(optimizer, feed_dict={_x: x_batch, _y_true: y_batch})\n",
    "\n",
    "                if epochs != data.train.epochs_completed:    \n",
    "                    break\n",
    "                    \n",
    "            epochs = data.test.epochs_completed\n",
    "            true_y = np.array([]) \n",
    "            pred_y = np.array([])\n",
    "            while True:\n",
    "                x_batch, y_batch = data.test.next_batch(train_batch_size)\n",
    "                \n",
    "                # Flatten only for NN nor for CNN\n",
    "                #x_batch = x_batch.reshape([train_batch_size, n_input])\n",
    "                #\n",
    "                \n",
    "                y_pred_batch = sess.run([y_pred], feed_dict= {_x: x_batch})#, _y_true: y_batch} )\n",
    "                \n",
    "                if len(true_y) == 0:\n",
    "                    true_y = y_batch\n",
    "                    pred_y = y_pred_batch[0]\n",
    "                else:\n",
    "                    true_y = np.concatenate((true_y, y_batch), axis=0)\n",
    "                    pred_y = np.concatenate((pred_y, y_pred_batch[0]), axis=0)\n",
    "\n",
    "                if epochs != data.test.epochs_completed:    \n",
    "                    break\n",
    "                    \n",
    "            true_y = true_y[:testLen]\n",
    "            pred_y = pred_y[:testLen]\n",
    "                    \n",
    "            ePitch = np.abs(true_y[:,0] - pred_y[:,0]) \n",
    "            eYaw = np.abs(true_y[:,1] - pred_y[:,1])\n",
    "            ListError = ePitch + eYaw\n",
    "            ListErrorPitch = ePitch\n",
    "            ListErrorYaw = eYaw\n",
    "\n",
    "            diff_true = true_y[:,0] + true_y[:,1]\n",
    "            diff_pred = pred_y[:,0] + pred_y[:,1]\n",
    "            RMSE = np.sqrt(np.mean(np.square(np.subtract(diff_pred, diff_true))))\n",
    "            RMSEPitch = np.sqrt(np.mean(np.square(np.subtract(pred_y[:,0], true_y[:,0]))))\n",
    "            RMSEYaw   = np.sqrt(np.mean(np.square(np.subtract(pred_y[:,1], true_y[:,1]))))\n",
    "            \n",
    "            op_assign_global_step = _global_step.assign(i)\n",
    "            \n",
    "            op_assign_error       = _error.assign(ListError.flatten())\n",
    "            op_assign_error_Pitch = _errorPitch.assign(ListErrorPitch.flatten())\n",
    "            op_assign_error_Yaw   = _errorYaw.assign(ListErrorYaw.flatten())\n",
    "            \n",
    "            op_assign_RMSE        = _RMSE.assign(RMSE)\n",
    "            op_assign_RMSE_Pitch  = _RMSEPitch.assign(RMSEPitch)\n",
    "            op_assign_RMSE_Yaw    = _RMSEYaw.assign(RMSEYaw)\n",
    "            \n",
    "            _ = sess.run([op_assign_global_step,\n",
    "                          op_assign_error, op_assign_error_Pitch, op_assign_error_Yaw,\n",
    "                          op_assign_RMSE, op_assign_RMSE_Pitch, op_assign_RMSE_Yaw])\n",
    "            \n",
    "            summary = sess.run(merged_summary)\n",
    "            train_writer.add_summary(summary,  i)\n",
    "\n",
    "            saver.save(sess, SAVE_PATH + \"model\", global_step=i, write_meta_graph=True)\n",
    "        \n",
    "            \n",
    "            with open(\"./\" + STORAGE_NAME + \"_\" + str(timestamp) + \".txt\", \"a\") as text_file:\n",
    "                text_file.write(\"%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s \\n\" %(\n",
    "                    i, RMSE, RMSEPitch, RMSEYaw,\n",
    "                    ListError.mean(), ListErrorPitch.mean(), ListErrorYaw.mean(),\n",
    "                    ListError.std(), ListErrorPitch.std(), ListErrorYaw.std(),\n",
    "                    time.time() - start_time))\n",
    "        \n",
    "            print ('%i RMSE: %.2f RMSE-P: %.2f RMSE-Y: %.2f e: %.2f E-P: %.2f E-Y: %.2f std: %.2f std-P: %.2f std-Y: %.2f time: %s' %(\n",
    "                    i, RMSE, RMSEPitch, RMSEYaw,\n",
    "                    ListError.mean(), ListErrorPitch.mean(), ListErrorYaw.mean(),\n",
    "                    ListError.std(), ListErrorPitch.std(), ListErrorYaw.std(),\n",
    "                    timedelta(seconds=int(round(time.time() - start_time)))))\n",
    "        \n",
    "        \n",
    "            if (i > breakEpochs - 1):\n",
    "                while (breakQueue.qsize() > breakEpochs):\n",
    "                    breakQueue.get(0)\n",
    "\n",
    "\n",
    "                break_mean = np.mean(list(breakQueue.queue))\n",
    "                break_mean\n",
    "                if (break_mean < RMSE):\n",
    "                    print(\"BREAK AFTER %i epochs\" % i)\n",
    "                    break\n",
    "                \n",
    "            breakQueue.put(RMSE)\n",
    "\n",
    "        # Ending time.\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Difference between start and end-times.\n",
    "        time_dif = end_time - start_time\n",
    "\n",
    "        # Print the time-usage.\n",
    "        print(\"Time usage: %s\" % timedelta(seconds=int(round(time_dif))))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
